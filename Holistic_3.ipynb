{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f8be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from glob import glob\n",
    "import shutil\n",
    "import math\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67c996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils #Drawing utilities\n",
    "mp_holistic = mp.solutions.holistic   #Holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba56e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width, frame_height = (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75667cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frame_per_video = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f9fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"WLASL/start_kit/WLASL_v0.3.json\", \"r\") as file:\n",
    "    content = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71398ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #color conversion\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b8c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f64f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmark(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                                mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe7bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ae2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_keypoints():\n",
    "    pose = np.zeros(132)\n",
    "    face = np.zeros(1404)\n",
    "    lh = np.zeros(21*3)\n",
    "    rh = np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e6d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820fbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirbyname(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ae48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_percent=0.90):\n",
    "    train_sequences, train_labels = [], []\n",
    "    test_sequences, test_labels = [], []\n",
    "    words = glob(\"Data_Numpy/*\")\n",
    "    for word in words:\n",
    "        actual_label = word.split(\"/\")[-1]\n",
    "        videos = glob(word + \"/*\")\n",
    "        #print(f\"-------------{actual_label}-------\")\n",
    "        train_proportion = math.ceil(round(train_percent * len(videos)))\n",
    "        for index,video_ in enumerate(videos):\n",
    "            #print(f\"********---> Video   {video_} ----- \")\n",
    "            window = []\n",
    "            for frame_num in range(1,num_frame_per_video+1):\n",
    "                np_file = f\"{video_}/{frame_num}.npy\"\n",
    "                #print(np_file)\n",
    "                res = np.load(np_file)\n",
    "                window.append(res)\n",
    "            if index <= train_proportion:\n",
    "                train_sequences.append(window)\n",
    "                train_labels.append(label_map[actual_label])\n",
    "            else:\n",
    "                test_sequences.append(window)\n",
    "                test_labels.append(label_map[actual_label])\n",
    "                \n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_sequences = np.array(test_sequences)\n",
    "    test_labels = np.array(test_labels)\n",
    "                \n",
    "    return train_sequences, train_labels, test_sequences, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80e97789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_frame(filename):\n",
    "    video_frame_count = 0\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return video_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32daea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\",\n",
    "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b68d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_video(content):\n",
    "    for i in content:\n",
    "        folder_path = f\"Data/{i['gloss']}\"\n",
    "        createFolder(folder_path)\n",
    "        for j in i['instances']:\n",
    "            if os.path.exists(f\"WLASL/start_kit/videos/{j['video_id']}.mp4\"):\n",
    "                shutil.copy(f\"WLASL/start_kit/videos/{j['video_id']}.mp4\", f\"Data/{i['gloss']}/{j['video_id']}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e14c0909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(content):\n",
    "    actions = []\n",
    "    for i in content:\n",
    "        actions.append(i['gloss'])\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e71d3",
   "metadata": {},
   "source": [
    "## Generate numpy data for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = glob(\"Data/*\")\n",
    "makedirbyname(\"Data_Numpy\")\n",
    "for word in words:\n",
    "    videos = glob(word + \"/*\")\n",
    "    for video in videos:\n",
    "        video_path = \"/\".join(\"\".join(video.split(\".\")[0:-1]).split(\"/\")[1:])\n",
    "        createFolder(f\"Data_Numpy/{video_path}\")\n",
    "        print(f\"Processing collection for... Data_Numpy/{video_path}\")\n",
    "        actual_video_frame = get_num_frame(video)\n",
    "        if actual_video_frame >= 75:\n",
    "            remind = actual_video_frame - 75\n",
    "            to_start = int(remind / 3)\n",
    "            j = 0\n",
    "            index = 0\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(video)\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        j+=1\n",
    "                        if j < to_start or j%3 != to_start%3:\n",
    "                            continue\n",
    "                        \n",
    "                        index+=1\n",
    "                        if index > 25:\n",
    "                            break\n",
    "                            \n",
    "                        if ret == False:\n",
    "                            cap.release()\n",
    "                            break\n",
    "                            \n",
    "                        cv2.imshow(video, frame)\n",
    "                        if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "                            break\n",
    "                            \n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            finally:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "        elif actual_video_frame >=50:\n",
    "            remind = actual_video_frame - 50\n",
    "            to_start = int(remind / 3)\n",
    "            j = 0\n",
    "            index = 0\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(video)\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        j+=1\n",
    "\n",
    "                        if j < to_start or j%2 != to_start%2:\n",
    "                            continue\n",
    "\n",
    "                        index+=1\n",
    "                        if index > 25:\n",
    "                            break\n",
    "\n",
    "                        if ret == False:\n",
    "                            cap.release()\n",
    "                            break\n",
    "\n",
    "                        cv2.imshow(video, frame)\n",
    "                        if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "                            break\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            finally:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "        elif actual_video_frame >=25:\n",
    "            remind = actual_video_frame - 25\n",
    "            to_start = int(remind / 3)\n",
    "            j = 0\n",
    "            index = 0\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(video)\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        j+=1\n",
    "\n",
    "                        if j < to_start:\n",
    "                            continue\n",
    "\n",
    "                        index+=1\n",
    "                        if index > 25:\n",
    "                            break\n",
    "\n",
    "                        if ret == False:\n",
    "                            cap.release()\n",
    "                            break\n",
    "\n",
    "                        cv2.imshow(video, frame)\n",
    "                        if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "                            break\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            finally:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "        else:\n",
    "            j = 0\n",
    "            index = 0\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(video)\n",
    "                with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                    while True:\n",
    "                        ret, frame = cap.read()\n",
    "                        j+=1\n",
    "\n",
    "                        if j < to_start:\n",
    "                            continue\n",
    "\n",
    "                        index+=1\n",
    "                        if index > 25:\n",
    "                            break\n",
    "\n",
    "                        if ret == False:\n",
    "                            cap.release()\n",
    "                            break\n",
    "\n",
    "                        cv2.imshow(video, frame)\n",
    "                        last_frame = frame\n",
    "                        if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "                            break\n",
    "\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "            finally:\n",
    "                while index <=25:\n",
    "                    cv2.imshow(video, last_frame)\n",
    "                    index+=1\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26840ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
