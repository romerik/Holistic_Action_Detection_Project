{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01315c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from glob import glob\n",
    "import shutil\n",
    "import math\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85e759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils #Drawing utilities\n",
    "mp_holistic = mp.solutions.holistic   #Holistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be84cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #color conversion\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce0002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2dff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmark(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                                mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2))\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a2c46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        # Drawing landmarks\n",
    "        draw_styled_landmark(image, results)\n",
    "        \n",
    "        cv2.imshow(\"OpenCV Feed\", image)\n",
    "\n",
    "        if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13259789",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6d9ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.right_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70812ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abacf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = []\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x, res.y, res.z, res.visibility])\n",
    "    pose.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe486a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93554c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a087ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af235e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987447a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282be21",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c60c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03575de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5591db5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results.face_landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c58a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c169394",
   "metadata": {},
   "outputs": [],
   "source": [
    "face.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ab319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ccfe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_keypoints():\n",
    "    pose = np.zeros(132)\n",
    "    face = np.zeros(1404)\n",
    "    lh = np.zeros(21*3)\n",
    "    rh = np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feb715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a56a3c",
   "metadata": {},
   "source": [
    "# Setup for collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cdf8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy array\n",
    "Data_Path = os.path.join(\"MP_Data\")\n",
    "\n",
    "#Actions that we try to detect\n",
    "actions = np.array([\"hello\", \"thanks\", \"iloveyou\"])\n",
    "\n",
    "#Thirty videos worth of data7\n",
    "no_sequence = 30\n",
    "\n",
    "#Videos are going to be 30 frames\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd9b84",
   "metadata": {},
   "source": [
    "## Create a folder for each action for recording its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5356e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for sequence in range(no_sequence):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(Data_Path, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93512bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob(\"Data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6913ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c2f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirbyname(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        shutil.rmtree(path)\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b093cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width, frame_height = (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f37fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frame_per_video = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f9430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = glob(\"Data/*\")\n",
    "makedirbyname(\"Data_Numpy\")\n",
    "for word in words:\n",
    "    videos = glob(word + \"/*\")\n",
    "    for video in videos:\n",
    "        idx = 1\n",
    "        video_path = \"/\".join(\"\".join(video.split(\".\")[0:-1]).split(\"/\")[1:])\n",
    "        createFolder(f\"Data_Numpy/{video_path}\")\n",
    "        print(f\"Processing collection for... Data_Numpy/{video_path}\")\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(video)\n",
    "            video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(f\"Number of frame = {video_frame_count}\")\n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    if ret == False:\n",
    "                        cap.release()\n",
    "                        break\n",
    "                        \n",
    "                    #Resize the frame\n",
    "                    resize_frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "                    \n",
    "                    # Make detections\n",
    "                    image, results = mediapipe_detection(resize_frame, holistic)\n",
    "                    \n",
    "                    # Drawing landmarks\n",
    "                    draw_styled_landmark(image, results)\n",
    "                    \n",
    "                    #Extracting keypoints\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    np.save(f\"Data_Numpy/{video_path}/{idx}\", keypoints)\n",
    "                    \n",
    "                    if idx == video_frame_count and video_frame_count < num_frame_per_video:\n",
    "                        idx+=1\n",
    "                        while idx<=num_frame_per_video:\n",
    "                            keypoints_blank = blank_keypoints()\n",
    "                            np.save(f\"Data_Numpy/{video_path}/{idx}\", keypoints_blank)\n",
    "                            idx+=1\n",
    "                        break\n",
    "                    elif idx == num_frame_per_video and video_frame_count > num_frame_per_video:\n",
    "                        break\n",
    "\n",
    "                    #cv2.imshow(video, image)\n",
    "                    #print(f\"Writing... Data_Numpy/{video_path}/{idx}.png\")\n",
    "                    #cv2.imwrite(f\"Data_Numpy/{video_path}/{idx}.png\", image)\n",
    "                    idx+=1\n",
    "\n",
    "                    if cv2.waitKey(10) and 0xFF == ord(\"q\"):\n",
    "                        break\n",
    "\n",
    "                cap.release()\n",
    "                #cv2.destroyAllWindows()\n",
    "        finally:\n",
    "            cap.release()\n",
    "            if idx < num_frame_per_video:\n",
    "                if os.path.exists(f\"Data_Numpy/{video_path}/{idx}.npy\"):\n",
    "                    idx+=1\n",
    "                while idx<=num_frame_per_video:\n",
    "                    keypoints_blank = blank_keypoints()\n",
    "                    np.save(f\"Data_Numpy/{video_path}/{idx}\", keypoints_blank)\n",
    "                    idx+=1\n",
    "                \n",
    "            #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014eef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(f\"{idx}.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de459c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/\".join(\"\".join(video.split(\".\")[0:-1]).split(\"/\")[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984f3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"computer\", \"book\", \"other\"] # Ecrire un script qui récupère tout ça du fichier JSOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5c0874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = get_actions(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ba768b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20496288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 19:34:38.988747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/romerik/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-04-04 19:34:38.988822: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da47ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num,label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82a9cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_percent=0.90):\n",
    "    train_sequences, train_labels = [], []\n",
    "    test_sequences, test_labels = [], []\n",
    "    words = glob(\"Data_Numpy/*\")\n",
    "    for word in words:\n",
    "        actual_label = word.split(\"/\")[-1]\n",
    "        videos = glob(word + \"/*\")\n",
    "        #print(f\"-------------{actual_label}-------\")\n",
    "        train_proportion = math.ceil(round(train_percent * len(videos)))\n",
    "        for index,video_ in enumerate(videos):\n",
    "            #print(f\"********---> Video   {video_} ----- \")\n",
    "            window = []\n",
    "            for frame_num in range(1,num_frame_per_video+1):\n",
    "                np_file = f\"{video_}/{frame_num}.npy\"\n",
    "                #print(np_file)\n",
    "                res = np.load(np_file)\n",
    "                window.append(res)\n",
    "            if index <= train_proportion:\n",
    "                train_sequences.append(window)\n",
    "                train_labels.append(label_map[actual_label])\n",
    "            else:\n",
    "                test_sequences.append(window)\n",
    "                test_labels.append(label_map[actual_label])\n",
    "                \n",
    "    train_sequences = np.array(train_sequences)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_sequences = np.array(test_sequences)\n",
    "    test_labels = np.array(test_labels)\n",
    "                \n",
    "    return train_sequences, train_labels, test_sequences, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeee7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences, train_labels, test_sequences, test_labels = get_data(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22440a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e86136",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a4f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05782443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a83e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(train_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54222c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab77c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(test_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e4ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839a4127",
   "metadata": {},
   "source": [
    "### Sample Video Data by name(gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e03e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls WLASL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ef884ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_frame(filename):\n",
    "    video_frame_count = 0\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        video_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return video_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbdca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num_frame(\"WLASL/start_kit/videos/05747.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9abbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration(filename):\n",
    "    result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\",\n",
    "                             \"format=duration\", \"-of\",\n",
    "                             \"default=noprint_wrappers=1:nokey=1\", filename],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT)\n",
    "    return float(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c3a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_duration(\"WLASL/start_kit/videos/05747.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"WLASL/start_kit/videos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frame = 0\n",
    "n=0\n",
    "for i in os.listdir(\"WLASL/start_kit/videos/\"):\n",
    "    frames.append(get_num_frame(f\"WLASL/start_kit/videos/{i}\"))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affeaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed21408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat WLASL/start_kit/WLASL_v0.3.json  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c9ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c23ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"WLASL/start_kit/WLASL_v0.3.json\", \"r\") as file:\n",
    "    content = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4078ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd34760",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"WLASL/start_kit/videos/00618.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8a2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_video(content):\n",
    "    for i in content:\n",
    "        folder_path = f\"Data/{i['gloss']}\"\n",
    "        createFolder(folder_path)\n",
    "        for j in i['instances']:\n",
    "            if os.path.exists(f\"WLASL/start_kit/videos/{j['video_id']}.mp4\"):\n",
    "                shutil.copy(f\"WLASL/start_kit/videos/{j['video_id']}.mp4\", f\"Data/{i['gloss']}/{j['video_id']}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folders_video(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7acc47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(content):\n",
    "    actions = []\n",
    "    for i in content:\n",
    "        actions.append(i['gloss'])\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc87471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in actions:\n",
    "    try:\n",
    "        for d in os.listdir(f\"Data_Numpy/{i}\"):\n",
    "            npy_file.append(len(os.listdir(f\"Data_Numpy/{i}/{d}\")))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(npy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file = np.array(npy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(npy_file==100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381ad92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
